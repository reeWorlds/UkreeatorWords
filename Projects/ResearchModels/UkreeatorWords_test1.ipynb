{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xPRljNbPK2BJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dvNSLA9CL0Yf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a73ddb48-2f0e-4712-ffa2-1817c17dd71d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "small words list size = 173228\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: windows-1251 -*-\n",
        "\n",
        "def readWords(path):\n",
        "  words = set()\n",
        "  try:\n",
        "    with open(path, 'r', encoding=\"utf-8\") as f:\n",
        "      words.update(set(f.read().split(\"\\n\")))\n",
        "  except:\n",
        "    with open(path, 'r', encoding=\"cp1251\") as f:\n",
        "      words.update(set(f.read().split(\"\\n\")))\n",
        "  words.discard(\"\")\n",
        "  return words\n",
        "\n",
        "def getAllWords(listNames):\n",
        "  allWords = set()\n",
        "\n",
        "  for name in listNames:\n",
        "    allWords.update(readWords(\"data/\" + name + \".txt\"))\n",
        "\n",
        "  return list(allWords)\n",
        "\n",
        "words_s = getAllWords([\"locations\", \"locations2\", \"names2\", \"names3\", \"words1\"])\n",
        "print(f\"small words list size = {len(words_s)}\")\n",
        "#words_f = getAllWords([\"locations\", \"locations2\", \"names2\", \"names3\", \"words1\", \"words2_1\", \"words2_2\"])\n",
        "#print(f\"full words list size = {len(words_f)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8n2SX7-HPPhd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c1bacc1-32f6-4654-f3b6-4a917f80dd9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique chars = 36\n",
            " '-абвгдежзийклмнопрстуфхцчшщьюяєіїґ\n"
          ]
        }
      ],
      "source": [
        "words_set = words_s\n",
        "\n",
        "chars = set()\n",
        "for word in words_set:\n",
        "  chars.update(set(word))\n",
        "chars = sorted(list(chars))\n",
        "\n",
        "print(\"Number of unique chars = \" + str(len(chars)))\n",
        "print(\"\".join(chars))\n",
        "\n",
        "ctoi = dict([(x, i) for i, x in enumerate(chars)])\n",
        "itoc = dict([(i, x) for i, x in enumerate(chars)])\n",
        "delim = len(chars)\n",
        "size = delim + 1\n",
        "ctoi['.'] = delim\n",
        "itoc[delim] = '.'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Log for different models:\n",
        "\n",
        "cnt2 (p = 1,369): train_llh = 2.586 valid_llh = 2.586\n",
        "\n",
        "cnt3 (p = 50,653): train_llh = 2.263 valid_llh = 2.276\n",
        "\n",
        "model1_tiny (p = 1,263): train_llh = 2.386 valid_llh = 2.382\n",
        "\n",
        "model1_normal (p = 10,617): train_llh = 2.169 valid_llh = 2.170\n",
        "\n",
        "model1_large (p = 25,165): train_llh = 2.061 valid_llh = 2.073\n",
        "\n",
        "model2_tiny (p = 899): train_llh = 2.445 valid_llh = 2.447\n",
        "\n",
        "model2_normal (p = 10,997): train_llh = 2.155 valid_llh = 2.163\n",
        "\n",
        "model2_large (p = 21,525): train_llh = 2.097 valid_llh = 2.109\n",
        "\n",
        "model3_tiny (p = 951): train_llh = 2.438 valid_llh = 2.433\n",
        "\n",
        "model3_normal (p = 10,965): train_llh = 2.191 valid_llh = 2.189\n",
        "\n",
        "model3_large (p = 29,829): train_llh = 2.112 valid_llh = 2.116"
      ],
      "metadata": {
        "id": "Dh0vE6oWW1Wl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "metadata": {
        "id": "u3ODp8qTae0Q"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2CiUq3QT-Of"
      },
      "outputs": [],
      "source": [
        "m1_input_len = 14\n",
        "\n",
        "def m1_align_word(word):\n",
        "  len_diff = (m1_input_len - 4) - len(word)\n",
        "  if len_diff < 0:\n",
        "    word = word[-m1_input_len + 4:]\n",
        "  if len_diff > 0:\n",
        "    word = (\".\" * len_diff) + word\n",
        "  word = \"..\" + word + \"..\"\n",
        "  return word\n",
        "\n",
        "def m1_split_word_into_tokens(word):\n",
        "  res = []\n",
        "  for i in range(len(word)):\n",
        "    res.append((m1_align_word(word[0:i]), word[i]))\n",
        "  res.append((m1_align_word(word), \".\"))\n",
        "  return res\n",
        "\n",
        "def m1_str_to_int(samples):\n",
        "  return [([ctoi[c] for c in sample[0]], ctoi[sample[1]]) for sample in samples]\n",
        "\n",
        "for x,y in m1_split_word_into_tokens(words_set[0]):\n",
        "  print(f\"{x} -> {y}\")\n",
        "\n",
        "m1_all_samples = []\n",
        "for word in words_set:\n",
        "  m1_all_samples.extend(m1_str_to_int(m1_split_word_into_tokens(word)))\n",
        "random.shuffle(m1_all_samples)\n",
        "\n",
        "print(f\"total of {len(m1_all_samples)} tokens\")\n",
        "\n",
        "m1_n_split = int(len(m1_all_samples) * 0.9)\n",
        "\n",
        "m1_x_trn = torch.tensor([sample[0] for sample in m1_all_samples[0:m1_n_split]])\n",
        "m1_y_trn = torch.tensor([sample[1] for sample in m1_all_samples[0:m1_n_split]])\n",
        "\n",
        "m1_x_vld = torch.tensor([sample[0] for sample in m1_all_samples[m1_n_split:]])\n",
        "m1_y_vld = torch.tensor([sample[1] for sample in m1_all_samples[m1_n_split:]])\n",
        "\n",
        "print(f\"train shape x = {m1_x_trn.shape} y = {m1_y_trn.shape}\")\n",
        "print(f\"validation shape x = {m1_x_vld.shape} y = {m1_y_vld.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m1_batch_size = 32\n",
        "m1_steps_in_epoch = m1_n_split // m1_batch_size\n",
        "\n",
        "m1_n_embd, m1_l1_channels, m1_l2_channels, m1_l3_channels, m1_head_channels = 2, 4, 8, 12, 12\n",
        "#m1_n_embd, m1_l1_channels, m1_l2_channels, m1_l3_channels, m1_head_channels = 12, 16, 24, 32, 64\n",
        "#m1_n_embd, m1_l1_channels, m1_l2_channels, m1_l3_channels, m1_head_channels = 24, 32, 48, 64, 64\n",
        "\n",
        "m1_leaky_relu_alpha = 0.05"
      ],
      "metadata": {
        "id": "xl7kSVRDizg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model1(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model1, self).__init__()\n",
        "\n",
        "    self.embedding = nn.Embedding(size, m1_n_embd)\n",
        "    nn.init.kaiming_normal_(self.embedding.weight, mode='fan_in')\n",
        "\n",
        "    self.l1 = nn.Conv1d(m1_n_embd, m1_l1_channels, 3)\n",
        "    nn.init.kaiming_normal_(self.l1.weight, mode='fan_in', nonlinearity='leaky_relu', a=m1_leaky_relu_alpha)\n",
        "    self.batch1 = nn.BatchNorm1d(m1_l1_channels)\n",
        "    self.activ1 = nn.LeakyReLU(m1_leaky_relu_alpha)\n",
        "\n",
        "    self.l2 = nn.Conv1d(m1_l1_channels, m1_l2_channels, 3, stride=3)\n",
        "    nn.init.xavier_uniform_(self.l2.weight)\n",
        "    self.batch2 = nn.BatchNorm1d(m1_l2_channels)\n",
        "    self.activ2 = nn.Tanh()\n",
        "\n",
        "    self.l3 = nn.Conv1d(m1_l2_channels, m1_l3_channels, 2, stride=2)\n",
        "    nn.init.xavier_uniform_(self.l3.weight)\n",
        "    self.batch3 = nn.BatchNorm1d(m1_l3_channels)\n",
        "    self.activ3 = nn.Tanh()\n",
        "\n",
        "    self.flat = nn.Flatten()\n",
        "    self.l4 = nn.Linear(2 * m1_l3_channels, m1_head_channels)\n",
        "    nn.init.xavier_uniform_(self.l4.weight)\n",
        "    self.batch4 = nn.BatchNorm1d(m1_head_channels)\n",
        "    self.activ4 = nn.Tanh()\n",
        "    \n",
        "    self.head = nn.Linear(m1_head_channels, size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.embedding(x).permute(0, 2, 1)\n",
        "    x = self.activ1(self.batch1(self.l1(x)))\n",
        "    x = self.activ2(self.batch2(self.l2(x)))\n",
        "    x = self.activ3(self.batch3(self.l3(x)))\n",
        "    x = self.activ4(self.batch4(self.l4(self.flat(x))))\n",
        "    x = self.head(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "H5ZdJunYfmbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = Model1()\n",
        "print(f\"Number of parameters in model1 = {count_parameters(model1)}\")"
      ],
      "metadata": {
        "id": "tKs5wTdx2aoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model training\n",
        "torch.manual_seed(74)\n",
        "m1_optimizer = torch.optim.AdamW(model1.parameters(), lr = 0.01, weight_decay = 0.001)\n",
        "m1_scheduler = torch.optim.lr_scheduler.ExponentialLR(m1_optimizer, gamma=0.5)\n",
        "\n",
        "def m1_getScore():\n",
        "  model1.eval()\n",
        "\n",
        "  t_batch = 256\n",
        "  train_llh, valid_llh = 0.0, 0.0\n",
        "  train_tot, valid_tot = 0, 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for i in range(t_batch, m1_x_vld.size(0), t_batch):\n",
        "      idx = torch.arange(i - t_batch, i, 1)\n",
        "      x, y = m1_x_vld[idx], m1_y_vld[idx]\n",
        "      \n",
        "      outputs = model1(x)\n",
        "      llh = F.cross_entropy(outputs, y)\n",
        "\n",
        "      valid_llh += llh.item() * t_batch\n",
        "      valid_tot += t_batch\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    for i in range(t_batch, m1_x_trn.size(0), t_batch):\n",
        "      idx = torch.arange(i - t_batch, i, 1)\n",
        "      x, y = m1_x_trn[idx], m1_y_trn[idx]\n",
        "      \n",
        "      outputs = model1(x)\n",
        "      llh = F.cross_entropy(outputs, y)\n",
        "\n",
        "      train_llh += llh.item() * t_batch\n",
        "      train_tot += t_batch\n",
        "  \n",
        "  valid_llh /= valid_tot\n",
        "  train_llh /= train_tot\n",
        "\n",
        "  return train_llh, valid_llh\n",
        "\n",
        "train_llh, valid_llh = m1_getScore()\n",
        "print(f\"epoch {-1} loss = {train_llh}   {valid_llh}\")\n",
        "\n",
        "for epoch in range(10):\n",
        "  model1.train()\n",
        "\n",
        "  for step in range(m1_steps_in_epoch):\n",
        "    m1_optimizer.zero_grad()\n",
        "\n",
        "    ix = torch.randint(0, m1_x_trn.size(0), (m1_batch_size,))\n",
        "    x, y = m1_x_trn[ix], m1_y_trn[ix]\n",
        "\n",
        "    outputs = model1(x)\n",
        "    loss = F.cross_entropy(outputs, y)\n",
        "\n",
        "    loss.backward()\n",
        "    m1_optimizer.step()\n",
        "  \n",
        "  m1_scheduler.step()\n",
        "  for param_group in m1_optimizer.param_groups:\n",
        "    param_group['weight_decay'] = [param_group['lr'] for param_group in m1_optimizer.param_groups][0] * 0.1\n",
        "\n",
        "  train_llh, valid_llh = m1_getScore()\n",
        "\n",
        "  print(f\"epoch {epoch} loss = {train_llh}   {valid_llh}\")"
      ],
      "metadata": {
        "id": "AZtcGqBY2_qA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = 'data/model1_large.pth'\n",
        "torch.save(model1.state_dict(), model_path)"
      ],
      "metadata": {
        "id": "kMMPWPp8bsIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "l = model1.embedding.weight.tolist()\n",
        "x_coords, y_coords = zip(*l)\n",
        "\n",
        "plt.figure(dpi=300)\n",
        "plt.scatter(x_coords, y_coords, s=400)\n",
        "\n",
        "# Add text labels to each point\n",
        "for i, (x, y) in enumerate(l):\n",
        "    plt.text(x, y, itoc[i], fontsize=12, ha='center', va='center')\n",
        "\n",
        "plt.xlabel('X-axis')\n",
        "plt.ylabel('Y-axis')\n",
        "plt.title('2D Points')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kmJVuzTbs93g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m2_input_len = 8\n",
        "\n",
        "def m2_align_word(word):\n",
        "  len_diff = m2_input_len - len(word)\n",
        "  if len_diff < 0:\n",
        "    word = word[-m2_input_len:]\n",
        "  if len_diff > 0:\n",
        "    word = (\".\" * len_diff) + word\n",
        "  return word\n",
        "\n",
        "def m2_split_word_into_tokens(word):\n",
        "  res = []\n",
        "  for i in range(len(word)):\n",
        "    res.append((m2_align_word(word[0:i]), word[i]))\n",
        "  res.append((m2_align_word(word), \".\"))\n",
        "  return res\n",
        "\n",
        "def m2_str_to_int(samples):\n",
        "  return [([ctoi[c] for c in sample[0]], ctoi[sample[1]]) for sample in samples]\n",
        "\n",
        "for x,y in m2_split_word_into_tokens(words_set[0]):\n",
        "  print(f\"{x} -> {y}\")\n",
        "\n",
        "m2_all_samples = []\n",
        "for word in words_set:\n",
        "  m2_all_samples.extend(m2_str_to_int(m2_split_word_into_tokens(word)))\n",
        "random.shuffle(m2_all_samples)\n",
        "\n",
        "print(f\"total of {len(m2_all_samples)} tokens\")\n",
        "\n",
        "m2_n_split = int(len(m2_all_samples) * 0.9)\n",
        "\n",
        "m2_x_trn = torch.tensor([sample[0] for sample in m2_all_samples[0:m2_n_split]])\n",
        "m2_y_trn = torch.tensor([sample[1] for sample in m2_all_samples[0:m2_n_split]])\n",
        "\n",
        "m2_x_vld = torch.tensor([sample[0] for sample in m2_all_samples[m2_n_split:]])\n",
        "m2_y_vld = torch.tensor([sample[1] for sample in m2_all_samples[m2_n_split:]])\n",
        "\n",
        "print(f\"train shape x = {m2_x_trn.shape} y = {m2_y_trn.shape}\")\n",
        "print(f\"validation shape x = {m2_x_vld.shape} y = {m2_y_vld.shape}\")"
      ],
      "metadata": {
        "id": "KLG_A3ITM0wt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m2_batch_size = 32\n",
        "m2_steps_in_epoch = m2_n_split // m2_batch_size\n",
        "\n",
        "#m2_n_embd, m2_l1_channels, m2_l2_channels, m2_head_channels = 2, 4, 8, 12\n",
        "#m2_n_embd, m2_l1_channels, m2_l2_channels, m2_head_channels = 24, 32, 40, 48\n",
        "m2_n_embd, m2_l1_channels, m2_l2_channels, m2_head_channels = 32, 48, 64, 64\n",
        "\n",
        "m2_leaky_relu_alpha = 0.05"
      ],
      "metadata": {
        "id": "1qj-u9_cSyMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model2, self).__init__()\n",
        "\n",
        "    self.embedding = nn.Embedding(size, m2_n_embd)\n",
        "    nn.init.kaiming_normal_(self.embedding.weight, mode='fan_in')\n",
        "\n",
        "    self.l1 = nn.Conv1d(m2_n_embd, m2_l1_channels, 2, stride = 2)\n",
        "    nn.init.kaiming_normal_(self.l1.weight, mode='fan_in', nonlinearity='leaky_relu', a=m2_leaky_relu_alpha)\n",
        "    self.batch1 = nn.BatchNorm1d(m2_l1_channels)\n",
        "    self.activ1 = nn.LeakyReLU(m2_leaky_relu_alpha)\n",
        "\n",
        "    self.l2 = nn.Conv1d(m2_l1_channels, m2_l2_channels, 2, stride=2)\n",
        "    nn.init.xavier_uniform_(self.l2.weight)\n",
        "    self.batch2 = nn.BatchNorm1d(m2_l2_channels)\n",
        "    self.activ2 = nn.Tanh()\n",
        "\n",
        "    self.flat = nn.Flatten()\n",
        "    self.l3 = nn.Linear(2 * m2_l2_channels, m2_head_channels)\n",
        "    nn.init.xavier_uniform_(self.l3.weight)\n",
        "    self.batch3 = nn.BatchNorm1d(m2_head_channels)\n",
        "    self.activ3 = nn.Tanh()\n",
        "    \n",
        "    self.head = nn.Linear(m2_head_channels, size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.embedding(x).permute(0, 2, 1)\n",
        "    x = self.activ1(self.batch1(self.l1(x)))\n",
        "    x = self.activ2(self.batch2(self.l2(x)))\n",
        "    x = self.activ3(self.batch3(self.l3(self.flat(x))))\n",
        "    x = self.head(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "tvyFEB6ES52f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Model2()\n",
        "print(f\"Number of parameters in model2 = {count_parameters(model2)}\")"
      ],
      "metadata": {
        "id": "itE1Cm1cUcBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model training\n",
        "torch.manual_seed(74)\n",
        "m2_optimizer = torch.optim.AdamW(model2.parameters(), lr = 0.01, weight_decay = 0.001)\n",
        "m2_scheduler = torch.optim.lr_scheduler.ExponentialLR(m2_optimizer, gamma=0.5)\n",
        "\n",
        "def m2_getScore():\n",
        "  model2.eval()\n",
        "\n",
        "  t_batch = 256\n",
        "  train_llh, valid_llh = 0.0, 0.0\n",
        "  train_tot, valid_tot = 0, 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for i in range(t_batch, m2_x_vld.size(0), t_batch):\n",
        "      idx = torch.arange(i - t_batch, i, 1)\n",
        "      x, y = m2_x_vld[idx], m2_y_vld[idx]\n",
        "      \n",
        "      outputs = model2(x)\n",
        "      llh = F.cross_entropy(outputs, y)\n",
        "\n",
        "      valid_llh += llh.item() * t_batch\n",
        "      valid_tot += t_batch\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    for i in range(t_batch, m2_x_trn.size(0), t_batch):\n",
        "      idx = torch.arange(i - t_batch, i, 1)\n",
        "      x, y = m2_x_trn[idx], m2_y_trn[idx]\n",
        "      \n",
        "      outputs = model2(x)\n",
        "      llh = F.cross_entropy(outputs, y)\n",
        "\n",
        "      train_llh += llh.item() * t_batch\n",
        "      train_tot += t_batch\n",
        "  \n",
        "  valid_llh /= valid_tot\n",
        "  train_llh /= train_tot\n",
        "\n",
        "  return train_llh, valid_llh\n",
        "\n",
        "train_llh, valid_llh = m2_getScore()\n",
        "print(f\"epoch {-1} loss = {train_llh}   {valid_llh}\")\n",
        "\n",
        "for epoch in range(10):\n",
        "  model2.train()\n",
        "\n",
        "  for step in range(m2_steps_in_epoch):\n",
        "    m2_optimizer.zero_grad()\n",
        "\n",
        "    ix = torch.randint(0, m2_x_trn.size(0), (m2_batch_size,))\n",
        "    x, y = m2_x_trn[ix], m2_y_trn[ix]\n",
        "\n",
        "    outputs = model2(x)\n",
        "    loss = F.cross_entropy(outputs, y)\n",
        "\n",
        "    loss.backward()\n",
        "    m2_optimizer.step()\n",
        "  \n",
        "  m2_scheduler.step()\n",
        "  for param_group in m2_optimizer.param_groups:\n",
        "    param_group['weight_decay'] = [param_group['lr'] for param_group in m2_optimizer.param_groups][0] * 0.1\n",
        "\n",
        "  train_llh, valid_llh = m2_getScore()\n",
        "\n",
        "  print(f\"epoch {epoch} loss = {train_llh}   {valid_llh}\")"
      ],
      "metadata": {
        "id": "IQXwJkD7UrLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = 'data/model2_large.pth'\n",
        "torch.save(model2.state_dict(), model_path)"
      ],
      "metadata": {
        "id": "K3mQeV9LVOJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "l = model2.embedding.weight.tolist()\n",
        "x_coords, y_coords = zip(*l)\n",
        "\n",
        "plt.figure(dpi=300)\n",
        "plt.scatter(x_coords, y_coords, s=400)\n",
        "\n",
        "# Add text labels to each point\n",
        "for i, (x, y) in enumerate(l):\n",
        "    plt.text(x, y, itoc[i], fontsize=12, ha='center', va='center')\n",
        "\n",
        "plt.xlabel('X-axis')\n",
        "plt.ylabel('Y-axis')\n",
        "plt.title('2D Points')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mNNu7FO5VUYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m3_input_len = 9\n",
        "\n",
        "def m3_align_word(word):\n",
        "  len_diff = m3_input_len - len(word)\n",
        "  if len_diff < 0:\n",
        "    word = word[-m3_input_len:]\n",
        "  if len_diff > 0:\n",
        "    word = (\".\" * len_diff) + word\n",
        "  return word\n",
        "\n",
        "def m3_split_word_into_tokens(word):\n",
        "  res = []\n",
        "  for i in range(len(word)):\n",
        "    res.append((m3_align_word(word[0:i]), word[i]))\n",
        "  res.append((m3_align_word(word), \".\"))\n",
        "  return res\n",
        "\n",
        "def m3_str_to_int(samples):\n",
        "  return [([ctoi[c] for c in sample[0]], ctoi[sample[1]]) for sample in samples]\n",
        "\n",
        "for x,y in m3_split_word_into_tokens(words_set[0]):\n",
        "  print(f\"{x} -> {y}\")\n",
        "\n",
        "m3_all_samples = []\n",
        "for word in words_set:\n",
        "  m3_all_samples.extend(m3_str_to_int(m3_split_word_into_tokens(word)))\n",
        "random.shuffle(m3_all_samples)\n",
        "\n",
        "print(f\"total of {len(m3_all_samples)} tokens\")\n",
        "\n",
        "m3_n_split = int(len(m3_all_samples) * 0.9)\n",
        "\n",
        "m3_x_trn = torch.tensor([sample[0] for sample in m3_all_samples[0:m3_n_split]])\n",
        "m3_y_trn = torch.tensor([sample[1] for sample in m3_all_samples[0:m3_n_split]])\n",
        "\n",
        "m3_x_vld = torch.tensor([sample[0] for sample in m3_all_samples[m3_n_split:]])\n",
        "m3_y_vld = torch.tensor([sample[1] for sample in m3_all_samples[m3_n_split:]])\n",
        "\n",
        "print(f\"train shape x = {m3_x_trn.shape} y = {m3_y_trn.shape}\")\n",
        "print(f\"validation shape x = {m3_x_vld.shape} y = {m3_y_vld.shape}\")"
      ],
      "metadata": {
        "id": "vJ-hDyKw0QSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m3_batch_size = 32\n",
        "m3_steps_in_epoch = m3_n_split // m3_batch_size\n",
        "\n",
        "m3_n_embd, m3_l1_channels, m3_head_channels = 2, 8, 12\n",
        "#m3_n_embd, m3_l1_channels, m3_head_channels = 16, 32, 64\n",
        "#m3_n_embd, m3_l1_channels, m3_head_channels = 32, 64, 96\n",
        "\n",
        "m3_leaky_relu_alpha = 0.05"
      ],
      "metadata": {
        "id": "Vq-9q0bD1EUi"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model3(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model3, self).__init__()\n",
        "\n",
        "    self.embedding = nn.Embedding(size, m3_n_embd)\n",
        "    nn.init.kaiming_normal_(self.embedding.weight, mode='fan_in')\n",
        "\n",
        "    self.l1 = nn.Conv1d(m3_n_embd, m3_l1_channels, 3, stride = 3)\n",
        "    nn.init.kaiming_normal_(self.l1.weight, mode='fan_in', nonlinearity='leaky_relu', a=m3_leaky_relu_alpha)\n",
        "    self.batch1 = nn.BatchNorm1d(m3_l1_channels)\n",
        "    self.activ1 = nn.LeakyReLU(m3_leaky_relu_alpha)\n",
        "\n",
        "    self.flat = nn.Flatten()\n",
        "    self.l2 = nn.Linear(3 * m3_l1_channels, m3_head_channels)\n",
        "    nn.init.xavier_uniform_(self.l2.weight)\n",
        "    self.batch2 = nn.BatchNorm1d(m3_head_channels)\n",
        "    self.activ2 = nn.Tanh()\n",
        "    \n",
        "    self.head = nn.Linear(m3_head_channels, size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.embedding(x).permute(0, 2, 1)\n",
        "    x = self.activ1(self.batch1(self.l1(x)))\n",
        "    x = self.activ2(self.batch2(self.l2(self.flat(x))))\n",
        "    x = self.head(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "x6A08uc32SRK"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = Model3()\n",
        "print(f\"Number of parameters in model3 = {count_parameters(model3)}\")"
      ],
      "metadata": {
        "id": "QU7kvL1d2_VQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model training\n",
        "torch.manual_seed(74)\n",
        "m3_optimizer = torch.optim.AdamW(model3.parameters(), lr = 0.01, weight_decay = 0.001)\n",
        "m3_scheduler = torch.optim.lr_scheduler.ExponentialLR(m3_optimizer, gamma=0.5)\n",
        "\n",
        "def m3_getScore():\n",
        "  model3.eval()\n",
        "\n",
        "  t_batch = 256\n",
        "  train_llh, valid_llh = 0.0, 0.0\n",
        "  train_tot, valid_tot = 0, 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for i in range(t_batch, m3_x_vld.size(0), t_batch):\n",
        "      idx = torch.arange(i - t_batch, i, 1)\n",
        "      x, y = m3_x_vld[idx], m3_y_vld[idx]\n",
        "      \n",
        "      outputs = model3(x)\n",
        "      llh = F.cross_entropy(outputs, y)\n",
        "\n",
        "      valid_llh += llh.item() * t_batch\n",
        "      valid_tot += t_batch\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    for i in range(t_batch, m3_x_trn.size(0), t_batch):\n",
        "      idx = torch.arange(i - t_batch, i, 1)\n",
        "      x, y = m3_x_trn[idx], m3_y_trn[idx]\n",
        "      \n",
        "      outputs = model3(x)\n",
        "      llh = F.cross_entropy(outputs, y)\n",
        "\n",
        "      train_llh += llh.item() * t_batch\n",
        "      train_tot += t_batch\n",
        "  \n",
        "  valid_llh /= valid_tot\n",
        "  train_llh /= train_tot\n",
        "\n",
        "  return train_llh, valid_llh\n",
        "\n",
        "train_llh, valid_llh = m3_getScore()\n",
        "print(f\"epoch {-1} loss = {train_llh}   {valid_llh}\")\n",
        "\n",
        "for epoch in range(10):\n",
        "  model3.train()\n",
        "\n",
        "  for step in range(m3_steps_in_epoch):\n",
        "    m3_optimizer.zero_grad()\n",
        "\n",
        "    ix = torch.randint(0, m3_x_trn.size(0), (m3_batch_size,))\n",
        "    x, y = m3_x_trn[ix], m3_y_trn[ix]\n",
        "\n",
        "    outputs = model3(x)\n",
        "    loss = F.cross_entropy(outputs, y)\n",
        "\n",
        "    loss.backward()\n",
        "    m3_optimizer.step()\n",
        "  \n",
        "  m3_scheduler.step()\n",
        "  for param_group in m3_optimizer.param_groups:\n",
        "    param_group['weight_decay'] = [param_group['lr'] for param_group in m3_optimizer.param_groups][0] * 0.1\n",
        "\n",
        "  train_llh, valid_llh = m3_getScore()\n",
        "\n",
        "  print(f\"epoch {epoch} loss = {train_llh}   {valid_llh}\")"
      ],
      "metadata": {
        "id": "20Aw82E33HMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = 'data/model3_large.pth'\n",
        "torch.save(model3.state_dict(), model_path)"
      ],
      "metadata": {
        "id": "UXujtf3c3j_D"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "l = model3.embedding.weight.tolist()\n",
        "x_coords, y_coords = zip(*l)\n",
        "\n",
        "plt.figure(dpi=300)\n",
        "plt.scatter(x_coords, y_coords, s=400)\n",
        "\n",
        "# Add text labels to each point\n",
        "for i, (x, y) in enumerate(l):\n",
        "    plt.text(x, y, itoc[i], fontsize=12, ha='center', va='center')\n",
        "\n",
        "plt.xlabel('X-axis')\n",
        "plt.ylabel('Y-axis')\n",
        "plt.title('2D Points')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "a7tLl5J43qCd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}